---
title: "EJA population genomics"
author: "Arthur Oulès"
date: "2/1/2023"
format: html
editor: source
---

# Load packages

```{r include=FALSE}
# Mandatory
library(here)

# Data analysis
library(pcadapt)
library(vcfR)
library(adegenet)
library(ape)

# External data acquisition for maps
library(ncdf4)
library(rnaturalearth)
library(rnaturalearthdata)
library(rnaturalearthhires)
library(marmap)

# External data acquisition for outliers BLAST
library(rentrez) #Allows to navigate NCBI database
library(xml2) #Allows xml file manipulation

# Making graph
library(tidyverse)
library(sf)
library(ggrepel)
library(ggpubr)
library(ggspatial)
library(RColorBrewer)
library(viridis)
library(scales)
library(ggnewscale)
```

# pcadapt analysis

## Functions

```{r}
reduce_all_numeric <- function(liste) {
  for (i in 1:length(liste)) {
    liste[i] <- as.numeric(liste[[i]][1])
  }
  liste
}

Get_outliers <- function(vcf_path, pcadapt, filename = NULL) {
  vcf_to_catalog_ranks <- paste0(vcf_path, "/populations.snps.vcf") |> # Vcf file from ustacks populations output is expected
    read.vcfR() |>
    getID() |>
    strsplit(split = ":") |>
    reduce_all_numeric()
  
  #Outliers selection by pcadapt pvalues
  padj <- pcadapt$pvalues |> p.adjust(method = "bonferroni")
  outliers_vcf_ranks <- which(padj < .1) #alpha = .1 chosen following https://bcm-uga.github.io/pcadapt/articles/pcadapt.html recommendations
  
  #Getting outliers catalog ranks
  outliers_catalog_ranks <- vcf_to_catalog_ranks[outliers_vcf_ranks]
  
  #Separating balancing selection from local adaptation (sorting outliers by phi_st)
  outliers_phi_st_filtered <- read.table( # tsv file from ustacks populations output is expected
    file             = paste0(vcf_path, "/populations.phistats.tsv"),
    header           = FALSE,
    sep              = "\t",
    skip             = 9,
    stringsAsFactors = FALSE
  ) |>
    select(c(1, 4)) |>
    rename("catalog_rank" = V1, "phi_st" = V4) |> 
    filter(catalog_rank %in% outliers_catalog_ranks) |>
    filter(phi_st > .1)
  print(
    paste0(
      "There are ",
      dim(outliers_phi_st_filtered)[1],
      " outliers with a phi_st > 0.1."
    )
  )
  #Saving outliers list as txt file for stacks2 whitelist analysis
  if (!is.null(filename)) {
    sink(here("output", paste0(filename, "_outliers_catalog_ranks.txt")))
    for (outlier in outliers_catalog_ranks){
      cat(paste0(outlier, "\n"), append = TRUE)
    }
    sink()
    
    print(
      paste0(
        "Outliers list saved as ",
        here("output", paste0(filename, "_outliers_catalog_ranks.txt"))
      )
    )
  }
  data.frame("vcf_ranks" = outliers_vcf_ranks, "catalog_ranks" = as.numeric(outliers_catalog_ranks))
}

Get_catalog_sequences <- function(catalog_path,
                                  outliers_ranks,
                                  filename = NULL) {
  catalog_sequences <- read.csv(# fasta file from ?output is expected
    catalog_path,
    col.names = c("Sequences"),
    stringsAsFactors = FALSE
  ) |>
    filter(row_number() %% 2 != 0) |>
    mutate("catalog_rank" = row_number()) |>
    select(catalog_rank, Sequences)
  
  outliers_sequences <- catalog_sequences |>
    filter(row_number() %in% outliers_ranks$catalog_ranks)
  
  if (!is.null(filename)) {
    write.csv(
      outliers_sequences,
      file = here("output", paste0(filename, ".csv"))
    )
    
    sink(here("output", paste0(filename, ".fa")))
    for (i in 1:dim(outliers_sequences)[1]){
      paste0(">", outliers_sequences$catalog_rank[i], "\n") |> cat(append = TRUE)
      paste0(outliers_sequences$Sequences[i], "\n") |> cat(append = TRUE)
    }
    sink()
  }
  outliers_sequences
}

XML_to_DF <- function(XML) {
  # Initialisation
  end <- length(xml_find_all(XML, ".//BlastOutput2"))
  counter <- 0
  query_df <- data.frame()
  # Main loop
  for (query in xml_find_all(XML, ".//BlastOutput2")) { # Reads XML BLAST results as data frame
    counter <- counter + 1
    # query_id <- 
    print(paste0("Extracting query ", counter, "/", end))
    print("Parsing hits")
    for (Hit in xml_find_all(query, ".//Hit")) { # For each locus get all hits
      match_1 <- xml_find_all(Hit, ".//Hsp") |> _[1] # Keep best match
      new_row <- data.frame(
        "query_number"     = xml_find_all(query, ".//query-title") |>
          xml_text() |> 
          as.numeric(),
        "hit_number"       = xml_find_all(Hit, ".//num") |>
          xml_text() |>
          _[1] |> 
          as.numeric(),
        "accession_number" = xml_find_all(Hit, ".//accession") |>
          xml_text() |>
          _[1],
        "title"            = xml_find_all(Hit, ".//title") |>
          xml_text() |>
          _[1],
        "organism"         = xml_find_all(Hit, ".//sciname") |>
          xml_text() |>
          _[1],
        "bit_score"        = xml_find_all(match_1, ".//bit-score") |>
          xml_text() |>
          as.numeric(),
        "eval_number"      = xml_find_all(match_1, ".//evalue") |>
          xml_text() |>
          as.numeric()
      )
      query_df <- query_df |>
        bind_rows(new_row)
    }
    print("End of parsing")
  }
  query_df
}

Get_protein_sequences <- function(query) {
  # Initialisation
  n_protein <- dim(query)[1]
  
  prot_sequences <- data.frame(
    "accession_number"  = query$accession_number,
    "sequences" = rep(NA, n_protein)
  )
  
  pb <- txtProgressBar(min = 0, max = n_protein, initial = 0) # Setup progress bar
  for (i in 1:n_protein) {
    sequence_info <- entrez_fetch(
      "nuccore",
      id      = prot_sequences$accession_number[i],
      rettype = "fasta_cds_aa",
      retmode = "text"
    ) # Fetch protein info from GenBank from accession number
    prot_sequences$sequences[i] <-
      sequence_info |>
      strsplit("]") |>
      unlist()|>
      tail(1) |> 
      gsub(pattern = "\n", replacement = "",  x = _) # Extract protein sequence from information
    setTxtProgressBar(pb, i) # Update progress bar
  }
  close(pb)
  prot_sequences
}
```

## All loci

### pcadapt pre-analysis to chose K value for outliers selection

```{r }
EJA_all_loci <- read.pcadapt(# Vcf file from ustacks populations output is expected
  here(
    "data",
    "ustacks_populations_output",
    "all_loci",
    "populations.snps.vcf"
  ),
  type = "vcf"
)

pcadapt(input = EJA_all_loci, K = 20) |>
  plot(option = "screeplot") # screeplot to visually chose pca component to keep
```

K = 3 seems to be the most optimal number of PCA axes to keep for this data set.

### Analysis with K = 3

```{r}
pcadapt_all_loci <- pcadapt(input = EJA_all_loci, K = 3)

popmap <- c(
  rep("carmel", 6),
  rep("monterey", 18),
  rep("palos_verdes", 9),
  rep("laguna", 9),
  rep("san_diego", 22),
  rep("catalina", 8),
  rep("punta_banda", 20),
  rep("cardon", 3)
) #map individuals to populations

plot(pcadapt_all_loci, option = "scores", pop = popmap, i = 1, j = 2)
plot(pcadapt_all_loci, option = "scores", pop = popmap, i = 2, j = 3)
plot(pcadapt_all_loci, option = "scores", pop = popmap, i = 1, j = 3)

plot(pcadapt_all_loci, option = "qqplot")
hist(
  pcadapt_all_loci$pvalues,
  xlab   = "p-values",
  main   = NULL,
  breaks = 50,
  col    = "orange"
)
```

### Outliers identification

```{r}
EJA_outliers_ranks <- Get_outliers(
  here("data", "ustacks_populations_output", "all_loci"),
  pcadapt  = pcadapt_all_loci,
  filename = "EJA",
  save     = TRUE
)
```

### Protein sequences acquisition for all loci analysis outliers

####Import and format the catalog

```{r}
EJA_outliers_sequences <- Get_catalog_sequences(
  here("data", "catalog.fa"),
  outliers_ranks = EJA_outliers_ranks,
  save_path      = "EJA_outliers_sequences"
)
```

Please run a NCBI nBLAST analysis with the generated .fa file and download the result as Single-file XML2

#### Import BLAST results saved as xml file and extract results

Please replace the second line of the XML file by "<BlastXML2>" which effectively removes the metadata from the first xml tag.

```{r}
EJA_outliers_query_df <- here("data", "8R1WY2TK01N-Alignment.xml") |> # "Single-file XML2" file from NCBI BLASTn output is expected
  read_xml() |>
  XML_to_DF()
EJA_outliers_query_df |> saveRDS(
  file = here("output", "EJA_outliers_nBlast_results_as_data_frame.RDS")
)
```


#### Filter BLAST results

```{r}
query_df_80_PREDICTED_unique_unique <- query_df |>
  filter(bit_score >= 80) |> # Keep only significant matches
  filter(grepl("PREDICTED", title)) |> # Keep only PREDICTED proteins. Removes non coding sequences and whole chromosome matches (causes problem when searching GeneBank)
  filter(!duplicated(query_number)) |> # Keep the first match for each locus
  filter(!duplicated(accession_number))  # Removes duplicated accession numbers
dim(query_df_80_PREDICTED_unique_unique)[1]

query_df_80_PREDICTED_unique_unique |> write.csv(
  file = here("output", "query_df_80_PREDICTED_unique_unique.csv")
)
```

#### Get protein sequences from GenBank

```{r}
# query_df <- readRDS(here("output", "Blast_results_as_data_frame.RDS"))
EJA_outliers_protein_sequences_matches <- Get_protein_sequences(
  query_df_80_PREDICTED_unique_unique
) |>
  filter(!sequences == "")
```

Save output as fasta file which can be sent to [blast KOALA](https://www.kegg.jp/blastkoala/).
```{r}
#Write protein sequences as fasta file with GenBank access number as sequence names
sink(here("output", "EJA_outliers_protein_sequences.fa"))
for (i in 1:dim(EJA_outliers_protein_sequences_matches[1])){
  cat(
    paste0(">", EJA_outliers_protein_sequences_matches$accession_number[i], "\n"),
    append = TRUE
  )
  cat(
    paste0(EJA_outliers_protein_sequences_matches$sequences[i], "\n"),
    append = TRUE
  )
}
sink()
```

#### Save outliers protein match table

```{r}
Table_2 <- query_df_80_PREDICTED_unique_unique |> 
  select(c(query_number, accession_number, title)) |>
  rename(Locus_ID = query_number) |>
  write.csv(file = here("output", "Table_2.csv"), row.names = FALSE)
```

## Blacklist (neutral loci)

```{r}
pcadapt_blacklist <- read.pcadapt( # vcf file from pcadapt analysis output is expected
  here(
    "data",
    "ustacks_populations_output",
    "EJA_blacklist",
    "populations.snps.vcf"
  ),
  type = "vcf"
) |> pcadapt(K = 20)

plot(pcadapt_blacklist, option = "screeplot")
plot(pcadapt_blacklist, option = "scores", pop = popmap, i = 1, j = 2)
```

## Whitelist (outliers loci)

```{r}
EJA_whitelist <- read.pcadapt( # vcf file from pcadapt analysis output is expected
  here(
    "data",
    "ustacks_populations_output",
    "EJA_whitelist_outliers",
    "populations.snps.vcf"
  ),
  type = "vcf"
)
pcadapt_whitelist <- pcadapt(input = EJA_whitelist, K = 20)

plot(pcadapt_whitelist, option = "screeplot")
plot(pcadapt_whitelist, option = "scores", pop = popmap, i = 1, j = 2)
```

## Analysis excluding Catalina

### pcadapt pre-analysis to chose K value

```{r}
EJA_all_loci_catalina <- read.pcadapt( # vcf file from pcadapt analysis output is expected
  here(
    "data",
    "ustacks_populations_output",
    "EJA_all_loci-catalina",
    "populations.snps.vcf"
  ),
  type = "vcf"
)

pcadapt_all_loci_catalina_raw <- pcadapt(input = EJA_all_loci_catalina, K = 20) #pcadapt analysis with high value of K
plot(pcadapt_all_loci_catalina_raw, option = "screeplot") #screeplot to visually chose pca component to keep
```

K = 2 seems to be the most optimal for this data set

### pcadapt analysis with K = 2

```{r}
pcadapt_all_loci_catalina <- pcadapt(input = EJA_all_loci_catalina, K = 2)

popmap <- c(
  rep("carmel", 6),
  rep("monterey", 18),
  rep("palos_verdes", 9),
  rep("laguna", 9),
  rep("san_diego", 22),
  rep("punta_banda", 20),
  rep("cardon", 3)
) #map individuals to populations

plot(
  pcadapt_all_loci_catalina,
  option = "scores",
  pop = popmap,
  i = 1, j = 2
)
100*pcadapt_all_loci_catalina$singular.values**2
```

### Outliers identification excluding Catalina

```{r}
EJA_catalina_outliers_ranks <- Get_outliers(
  vcf_path = here(
    "data",
    "ustacks_populations_output",
    "EJA_all_loci-catalian"
  ),
  pcadapt  = pcadapt_all_loci_catalina,
  filename = "EJA_catalina",
  save     = FALSE
)
```

# Figures

## Functions

```{r}
manhattan_plot_custom <- function( # Draws a manhattan plot using ggplot()
  vcf_file, # vcf file from ustacks population analysis
  pcadapt_analysis, # Output from the pcadapt() function
  n_chromosome, # Number of effective chromosomes
  outliers_ranks = NULL # Output from the Get_outliers() function
) {
  chromosome_names <- vcf_file |> # Extract chromosome number map from vcf info
  getFIX() |>
  _[, "CHROM"] |>
  lapply(FUN = gsub, pattern = "SCAF_", replacement = "") |>
  as.integer()
  
  # Getting x axis coordinates for chromosome id positions
  mid_pos <- rep(NA, n_chromosome) # Initialize midrank vector
  count_pos <- table(chromosome_names) |> as.data.frame() # Number of locus per chromosome
  
  for (i in 1:n_chromosome){
    mid_pos[i] <-
      Position(function(x) x == i, chromosome_names) + count_pos$Freq[i]/2
  }
  
  notNA.idx <- !is.na(pcadapt_analysis$pvalues)
  
  manhattan_df <- data.frame(
    x   = which(notNA.idx), # Catalog rank of locus with non-NA pcadapt p-value 
    y   = -as.numeric( # Gets non adjusted -log10(pvalues) without infinite values
      pchisq(
        pcadapt_analysis$chi2.stat[notNA.idx],
        df         = attr(pcadapt_analysis, "K"),
        lower.tail = FALSE,
        log.p      = TRUE
      )/log(10)
    ), 
    chr = chromosome_names%%2 |> _[notNA.idx] # Chromosome colour mapping
  )
  
  manhattan_plot <- ggplot(manhattan_df, aes(x = x, y = y)) +
    geom_point(aes(colour = factor(chr))) +
    guides(colour = FALSE) +
    scale_color_manual(values = c("black", "grey")) +
    scale_x_continuous(breaks = mid_pos, labels = 1:24) +
    labs(x = "chromosome", y = "-log10(p-value)") +
    theme_bw() +
    theme(
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank()
    )
  
  if (!is.null(outliers_ranks)) {
    outliers_pvalues_rank <- data.frame(
      "vcf_rank"                 = outliers_ranks$vcf_rank,
      "catalog_rank"             = as.character(outliers_ranks$catalog_ranks),
      "outliers_-log10(pvalues)" = -log10(
        pcadapt_analysis$pvalues[outliers_ranks$vcf_ranks]
      ),
      "outliers_pvalue_plot"     =
        manhattan_df$y[manhattan_df$x %in% outliers_ranks$vcf_ranks]
    )
    
    manhattan_plot_labels <- manhattan_plot +
      geom_label_repel(
        data    = outliers_pvalues_rank,
        mapping = aes(x = vcf_rank, y = outliers_pvalue_plot, label = catalog_rank)
      ) #Manhattan plot with outliers catalog ranks
    manhattan_plot_labels
  } else {
    manhattan_plot
  }
}

PCA_plot <- function(pcadapt_output, popmap, x_offsets, y_offsets) {
  #Format data frame
  PCA_df <- data.frame(
    "x"   = -pcadapt_output$scores[, 1],
    "y"   = -pcadapt_output$scores[, 2],
    "pop" = popmap
  )
  
  populations <- popmap |> as.factor() |> levels()

  PCA_average <- data.frame("pop" = populations)
  for (i in 1:length(PCA_average$pop)){
    PCA_average$average_x[i] <- PCA_df |> 
      filter(pop == PCA_average$pop[i]) |> 
      pull(x) |>
      mean()
    PCA_average$average_y[i] <- PCA_df |> 
      filter(pop == PCA_average$pop[i]) |> 
      pull(y) |>
      mean()
  }
  
  PCA_average$pop <- populations |>
    str_to_title() |>
    gsub(pattern = "_", x = _, replacement = " ")

  # Add offsets
  PCA_average$average_x <- PCA_average$average_x + x_offsets
  
  PCA_average$average_y <- PCA_average$average_y - y_offsets
  
  PCA_percentages <- pcadapt_output$singular.values^2 |> percent()
  
  # ggplot prompt
  PCA <- ggplot() +
    geom_point(
      PCA_df,
      mapping = aes(x = y, y = x, fill = pop),
      size = 3,
      shape = 21
    ) +
    geom_text(
      PCA_average,
      mapping = aes(x = average_y, y = average_x, label = pop)
    ) +
    labs(
      x = paste0("-PC2: ", PCA_percentages[2]),
      y = paste0("-PC1: ", PCA_percentages[1])
    ) +
    coord_fixed(ratio = 1.2) +
    theme(
      legend.position  = "none",
      panel.background = element_rect(
        fill = "white",
        color = "black"
      ),
      panel.grid.major = element_line(
        color = "black",
        linetype = "dashed",
        linewidth = .12
      )
    )
  PCA
}

nc_crop <- function(var, lon_min, lon_max, lat_min, lat_max) {
  # Coordinates conversion
  lon_min <- lon_min * 10
  lon_max <- lon_max * 10
  if (lon_min < 0) {
    lon_min <- 3600 + lon_min
  }
  if (lon_max < 0) {
    lon_max <- 3600 + lon_max
  }
  lat_min <- lat_min * 10 + 750
  lat_max <- lat_max * 10 + 750
  
  # Get and crop data
  var_crop <- ncvar_get(var) |>
  _[, , 1] |>
  as.matrix() |>
  _[(lon_min):(lon_max), (lat_min):(lat_max)] |>
  as.vector()
  
  var_crop
}

reduce_density <- function(high_density_vector, factor) {
  high_density_vector |>
    data.frame("value" = _) |>
    mutate(value = ifelse(row_number() %% factor == 1, value, NA)) |> # Reduce vector density
    pull(value)
}
```

## Figure 1 - Manhattan plot homemade

### Getting data

```{r}
EJA_all_loci_vcf <- here(
  "data",
  "ustacks_populations_output",
  "all_loci",
  "populations.snps.vcf"
) |>
  read.vcfR() # vcf file from pcadapt analysis output is expected
```

### Generate plot without points labels

```{r}
manhattan_plot <- manhattan_plot_custom(
  vcf_file         = EJA_all_loci_vcf,
  pcadapt_analysis = pcadapt_all_loci,
  n_chromosome     = 24
)

ggsave(
  here("output", "plots", "manhattan_plot.pdf"),
  plot = manhattan_plot,
  width = 16,
  height = 7
)
system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "manhattan_plot.pdf")),
  wait = FALSE
)
```

### Generate plot with points labels

```{r}
manhattan_plot_labels <- manhattan_plot_custom(
  vcf_file         = EJA_all_loci_vcf,
  pcadapt_analysis = pcadapt_all_loci,
  n_chromosome     = 24,
  outliers_ranks   = EJA_outliers_ranks
)

ggsave(
  here("output", "plots", "manhattan_plot_labels.pdf"),
  plot = manhattan_plot_labels,
  width = 16,
  height = 7
); system2(
  "open",
  args = c(
    "-a Preview.app",
    here("output", "plots", "manhattan_plot_labels.pdf")
  ),
  wait = FALSE
)
```

## Figure 2 - PCA & map

### PCA plot

```{r}
PCA <- PCA_plot(
  pcadapt_output = pcadapt_all_loci,
  popmap = popmap,
  x_offsets = c(0, -.02, .015, 0, 0, 0, 0, 0),
  y_offsets = c(.04, .01, -.01, .06, .06, .06, .055, .045)
)
```

### Surface temperature and current map


#### Getting data

Extracting ocean surface temperature and current from [BRAN2020](https://research.csiro.au/bluelink/global/reanalysis/) 
[Dataset](https://dapds00.nci.org.au/thredds/catalog/gb6/BRAN/BRAN2020/catalog.html).\
[Tutorial on NetCDF4 files](https://towardsdatascience.com/how-to-crack-open-netcdf-files-in-r-and-extract-data-as-time-series-24107b70dcd)

```{r}
nc_temp <- nc_open(here("data","ocean_temp_ann_2022.nc"))
# Longitude's 0 is at Greenwich and -180 become 3600
# Latitudes start at -75 and end at +75
# To convert add +360 to longitude and +75 to latitude
nc_u   <- nc_open(here("data", "ocean_u_ann_2022.nc"))
nc_v   <- nc_open(here("data", "ocean_v_ann_2022.nc"))
```

#### Formatting data

##### BRAN2020 data

```{r}
# Coordinates of interest
lon_min <- -130.0
lon_max <- -110.0
lat_min <- 20.0
lat_max <- 40.0

# Convert coordinate system
lon <- nc_temp |> ncvar_get("xt_ocean")
lon[1801:3600] <- seq(-179.95, -0.05, .1)
lat <- nc_temp |> ncvar_get("yt_ocean")

# Fuse for use in ggplot and crop to smaller size for faster computing time
crop_lonlat <- expand.grid(
  "lon" = lon[(3600 + 10 * lon_min):(3600 + 10 * lon_max)],
  "lat" = lat[(750 + 10 * lat_min):(750 + 10 * lat_max)]
)

crop_temp <- nc_temp |> nc_crop(lon_min, lon_max, lat_min, lat_max)

crop_u_lowres <- nc_u |>
  nc_crop(lon_min, lon_max, lat_min, lat_max) |> 
  reduce_density(2)

crop_v_lowres <- nc_v |>
  nc_crop(lon_min, lon_max, lat_min, lat_max) |> 
  reduce_density(2)

map_data_lowres_df <- crop_lonlat |>
  mutate("temp" = crop_temp, "u" = crop_u_lowres, "v" = crop_v_lowres)

current_uv_scalar <- 2 # Set scalar for better vector visibility, don"t forget when setting scale in final graph
```

###### Memory cleanup

```{r}
rm(
  nc_temp, nc_u, nc_v,
  lon, lat,
  crop_temp, crop_u_lowres, crop_v_lowres
) # Clear unused big variables
gc()
```

##### Landmass

```{r}
# Setting up landmass map from naturalearth
states <- ne_states(
  country     = c("united states of america", "mexico"),
  returnclass = "sf"
)

# Sampling site coordinates and misc info on map
sample_sites <- read.csv(
    here("data","EJA_RAD_sampling_sites.csv"),
    stringsAsFactors = FALSE
  ) |>
  filter(!duplicated(Sampling_location)) |> 
  mutate( # Add offsets
    "lab_lon" = Longitude + .15 + c(0, 0, 0, .1, 0, 0, 0, -.1 -2),
    "lab_lat" = Latitude + .25 + c(0, -.5, 0, -.2, 0, 0, 0, -.1 -1)
  )

states_labels <- data.frame(
  "long" = c(-117.5, -115.5, -113.7, -115.2),
  "lat"  = c(35.5, 36.6, 35, 30.25),
  "lab"  = c("CA", "NV", "AZ", "BC")
)
city_labels <- data.frame(
  "lat"      = c(37.773972, 34.448113),
  "long"     = c(-122.431297, -120.471439),
  "lat_lab"  = c(37.9, 34.8),
  "long_lab" = c(-122.28, -120.535),
  "lab"      = c("San Francisco", "Point\nConception")
)
ocean_labels <- data.frame(
  "long" = c(-121,-113.85),
  "lat"  = c(31,30.7),
  "lab"  = c("Pacific Ocean","Gulf\nof\nCalifornia")
)
```

#### Generate map

[Tutorial for surface temperature and current speed map](https://theoceancode.netlify.app/post/mapping_with_ggplot2/)

```{r}
map <- ggplot() +
  # Temperature map
  geom_tile(
    mapping = aes(x = lon, y = lat, fill = temp),
    data    =  map_data_lowres_df
  ) +
  # Temperature scale
  scale_fill_viridis(name = "Temp.\n(°C)", option = "turbo") +
  # Current vectors
  geom_segment(
    data    = map_data_lowres_df,
    mapping = aes(
      x    = lon,
      y    = lat,
      xend = lon + current_uv_scalar * u,
      yend = lat + current_uv_scalar * v
    ),
    arrow   = arrow(angle = 15, length = unit(0.035, "inches"), type = "closed"),
    na.rm   = TRUE,
    alpha   = 0.3
  ) +
  # Landmass
  geom_sf(data = states) +
  # Crop map
  coord_sf(xlim = c(-124, -113), ylim = c(28.5, 38.5), expand = FALSE) +
  # Sampling sites points and labels
  new_scale("fill") +
  geom_path( # Path from Catalina label to Catalina island
    data.frame(
      "x" = c(-118.4163, -118.4163 -.85),
      "y" = c(33.38790, 33.38790 -.73)
    ),
    mapping = aes(x, y)
  ) +
  geom_point(
    sample_sites,
    mapping     = aes(
      x = Longitude,
      y = Latitude,
      fill = Sampling_location,
      size = 1.3
    ),
    shape       = 21,
    show.legend = FALSE
  ) +
  geom_label(
    sample_sites,
    mapping = aes(x = lab_lon, y = lab_lat, label = Sampling_location),
    hjust   = 0
  ) +
  # Extra cities points and labels
  geom_point(
    city_labels,
    mapping     = aes(x = long, y = lat),
    size        = 4,
    shape       = 20,
    show.legend = FALSE
  ) +
  geom_text(
    city_labels,
    mapping    = aes(x = long_lab, y = lat_lab, label = lab),
    lineheight = .7,
    hjust      = 0
  ) +
  # Ocean and state names
  geom_text(
    states_labels,
    mapping = aes(x = long, y = lat, label = lab),
    size = 5.5
  ) +
  geom_text(
    ocean_labels[2, ],
    mapping = aes(x = long, y = lat, label = lab),
    colour  = "ivory",
    size    = 5
  ) +
  geom_label(
    ocean_labels[1, ],
    mapping       = aes(x = long, y = lat, label = lab),
    colour        = "black",
    size          = 5,
    label.padding = unit(0.5, "lines")
  ) +
  # Vector scale
  geom_label(
    aes(x = -122, y = 29.5, label = "1.0 m/s\n"),
    size          = 4.5,
    label.padding = unit(0.5, "lines")
  ) +
  geom_segment(
    aes(x = -122.5, y = 29.25, xend = -121.5, yend = 29.25),
    arrow = arrow(angle = 15, length = unit(0.035, "inches"), type = "closed")
  ) +
  # Cartographic scale
  geom_label(aes(x = -119.1, y = 28.71, label = "        ")) +
  annotation_scale(location = "bl", width_hint = 0.4) +
  # Orientation
  annotation_north_arrow(
    location = "tr",
    style = north_arrow_fancy_orienteering()
  ) +
  # Axes
  labs(x = "Longitude", y = "Latitude") +
  scale_x_continuous(
    breaks = c(-120, -115),
    labels = c("120°W", "115°W")
  ) +
  scale_y_continuous(
    breaks = c(30, 35),
    labels = unit_format(suffix = "°N", sep = "")
  )

ggsave(
  here("output", "plots", "temp_current_map.pdf"),
  plot   = map,
  width  = 9,
  height = 9
)

system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "temp_current_map.pdf")),
  wait = FALSE
)
```

##### Memory cleanup

```{r}
rm(map, states,
   sample_sites, states_labels, city_labels, ocean_labels,
   current_uv_scalar)
gc()
```


### Fuse PCA plot and map

```{r}
PCA_map <- ggarrange(PCA, map, widths = c(1, 1.3))

ggsave(
  here("output", "plots", "pca_map.pdf"),
  plot   = PCA_map,
  width  = 14,
  height = 9
)
system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "pca_map.pdf")),
  wait = FALSE
)
```

## Figure 3? - Bathymetry

### Generating bathymetry map

#### Getting and formatting data

```{r}
nc_u   <- nc_open(here("data", "ocean_u_ann_2022.nc"))
nc_v   <- nc_open(here("data", "ocean_v_ann_2022.nc"))

crop_u <- nc_u |>
  nc_crop(lon_min, lon_max, lat_min, lat_max)
crop_v <- nc_v |>
  nc_crop(lon_min, lon_max, lat_min, lat_max)
```


```{r}
catalina_df <-
  getNOAA.bathy(
    lon1 = -121,
    lon2 = -116,
    lat1 = 32,
    lat2 = 35,
    resolution = .5
  ) |> 
  fortify.bathy() |>
  mutate(z = ifelse(z > 0, NA, z)) # Remove landmass data

map_data_df <- data.frame( # Get surface current vectors
  crop_lonlat,
  "u" = crop_u,
  "v" = crop_v
)
```

#### Generate map

```{r}
bathy <- ggplot() +
  # Plot bathymetry
  geom_raster(data = catalina_df, mapping = aes(x = x, y = y, fill = z)) +
  # Plot landmass
  geom_sf(data = states) +
  # Plot surface current speed
  geom_segment(
    data    = map_data_df,
    mapping = aes(x = lon, y = lat, xend = lon + u * 1, yend = lat + v * 1),
    arrow   = arrow(angle = 15, length = unit(0.04, "inches"), type = "closed"),
    na.rm   = TRUE,
    alpha   = 0.3
  ) +
  # Plot sampling sites
  geom_point(
    sample_sites[c(3,4,5,8),],
    mapping     = aes(x = Longitude, y = Latitude, size = 1.3),
    show.legend = FALSE
  ) +
  geom_label(
    sample_sites[c(3,4,5,8),],
    mapping = aes(x = Longitude, y = Latitude, label = Sampling_location),
    hjust   = 0,
    nudge_x = .05,
    nudge_y = .1
  ) +
  # Plot extra landmark
  geom_point(
    city_labels[2, ],
    mapping     = aes(x = long, y = lat),
    size        = 4,
    shape       = 20,
    show.legend = FALSE
  ) +
  geom_text(
    city_labels[2, ],
    mapping = aes(x = long, y = lat, label = lab),
    lineheight = .7,
    hjust = 0,
    nudge_x = .05,
    nudge_y = .1
  ) +
  # Plot scales
  scale_fill_gradient(
    name = "Depth (m)",
    low = "dodgerblue4",
    high="gainsboro"
  ) +
  geom_label(
    aes(x = -120.4, y = 32.3, label = ".25 m/s\n"),
    size = 4.5,
    label.padding = unit(0.5, "lines")
  ) +
  geom_segment(
    aes(x = -120.52, y = 32.25, xend = -120.27, yend = 32.25),
    arrow = arrow(angle = 15, length = unit(0.04, "inches"), type = "closed")
  ) +
  geom_label(aes(x = -119.705, y = 32.08, label = "        ")) +
  annotation_scale(location = "bl", width_hint = 0.4) +
  annotation_north_arrow(
    location = "tr",
    style    = north_arrow_fancy_orienteering()
  ) +
  # Crop map
  coord_sf(xlim = c(-121, -116), ylim = c(32, 35), expand = FALSE) +
  # Axis labels and theme
  labs(x = "Longitude", y = "Latitude") +
  scale_y_continuous(
    breaks = seq(32, 35, 1),
    labels = unit_format(suffix = "°N", sep = "")
  ) +
  theme(
    legend.position = c(.93, .73),
    plot.margin     = margin(t = 0, r = 1, b = 0, l = .5, unit = "cm")
  )
  
ggsave(
  here("output", "plots", "bathy.pdf"),
  plot = bathy,
  width = 9,
  height = 7
)
system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "bathy.pdf")),
  wait = FALSE
)
```

## Blank map

```{r}
map_blank <- ggplot() +
  # Landmass
  geom_sf(data = states) +
  # Sampling sites points and labels
  new_scale("fill") +
  geom_path(
    mapping = aes(x, y),
    data    = data.frame(
      "x" = c(-118.4163, -118.4163 -.85),
      "y" = c(33.38790, 33.38790 -.73)
    )
  ) +
  geom_point(
    sample_sites,
    mapping     = aes(
      x    = Longitude,
      y    = Latitude,
      fill = Sampling_location,
      size = 1.3
    ),
    shape       = 21,
    show.legend = FALSE
  ) +
  geom_label(
    sample_sites,
    mapping = aes(x = lab_lon, y = lab_lat, label = Sampling_location),
    hjust   = 0
  ) +
  geom_point(
    city_labels,
    mapping     = aes(x = long, y = lat),
    size        = 4,
    shape       = 20,
    show.legend = FALSE
  ) +
  geom_text(
    city_labels,
    mapping    = aes(x = long_lab, y = lat_lab, label = lab),
    lineheight = .7,
    hjust      = 0
  ) +
  # Ocean and state names
  geom_text(
    states_labels,
    mapping = aes(x = long, y = lat, label = lab),
    size    = 5.5
  ) +
  geom_text(
    ocean_labels[2,],
    mapping = aes(x = long, y = lat, label = lab),
    colour  = "ivory",
    size    = 5
  ) +
  geom_label(
    ocean_labels[1,],
    mapping       = aes(x = long, y = lat, label = lab),
    colour        = "black",
    size          = 5,
    label.padding = unit(0.5, "lines")
  ) +
  # Crop map 
  coord_sf(xlim = c(-124, -113), ylim = c(28.5, 38.5), expand = FALSE) +
  # Vector, temperature and distance scale + orientation
  geom_label(aes(x = -119.1, y = 28.71, label = "        ")) +
  annotation_scale(location = "bl", width_hint = 0.4) +
  annotation_north_arrow(
    location = "tr",
    style = north_arrow_fancy_orienteering()
  ) +
  # Set text around map and coordinates display
  labs(x = "Longitude", y = "Latitude") +
  scale_x_continuous(
    breaks = c(-120, -115),
    labels = c("120°W","115°W")
  ) +
  scale_y_continuous(
    breaks = c(30, 35),
    labels = unit_format(suffix = "°N", sep = "")
  ) +
  theme(panel.background = element_rect("lightblue"))

ggsave(
  here("output", "plots", "map_blank.pdf"),
  plot = map_blank,
  width = 7.5,
  height = 7.5
)

system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "map_blank.pdf")),
  wait = FALSE
)
```

## Figure 4? - Protein sequences annotation

### Convert blast KOALA pie piechart in barplot

```{r}
koala_results <- read.csv( # File downloaded from https://www.kegg.jp/blastkoala/ is expected
  here("external_results", "Blast_koala_results.csv"),
  stringsAsFactors = FALSE
) |>
  mutate(
    Functional.category = factor(Functional.category, Functional.category)
  )

koala_barplot <- ggplot(
    koala_results,
    mapping = aes(
      x    = Functional.category,
      y    = Counts,
      fill = Functional.category
    )
  ) +
  geom_col() +
  scale_fill_manual(
    name   = "Functional category",
    labels = koala_results$Functional.category,
    values = koala_results$colour,
    breaks = koala_results$Functional.category
  ) +
  theme(
    panel.background   = element_rect(fill = "white", colour = "black"),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_line(
      colour    = "black",
      linetype  = "solid",
      linewidth = .12
    ),
    panel.grid.minor.y = element_line(
      colour    = "black",
      linetype  = "dashed",
      linewidth = .08
    ),
    axis.ticks.x      = element_blank(),
    axis.text.x       = element_blank(),
    axis.title.x      = element_blank()
  )
ggsave(
  filename = here("external_results", "blast_koala_bar_plot.pdf"),
  plot     = koala_barplot,
  width    = 21,
  height   = 10,
  units    = "cm"
)
system2(
  "open",
  args = c(
    "-a Preview.app",
    here("external_results", "blast_koala_bar_plot.pdf")
  ),
  wait = FALSE
)
```
