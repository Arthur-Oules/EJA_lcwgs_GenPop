---
title: "EJA population genomics"
author: "Arthur Oul√®s"
date: "2/1/2023"
format: html
editor: source
---

# Load packages

```{r include=FALSE}
#Mandatory
library(here)

#Data analysis
library(pcadapt)
library(vcfR)
library(adegenet)
library(ape)

#External data acquisition for maps
library(ncdf4)
library(rnaturalearth)
library(rnaturalearthdata)
library(rnaturalearthhires)
library(marmap)

#External data acquisition for outliers BLAST
library(rentrez) #Allows to navigate NCBI database
library(xml2) #Allows xml file manipulation

#Making graph
library(tidyverse)
library(sf)
library(ggrepel)
library(ggpubr)
library(ggspatial)
library(RColorBrewer)
library(viridis)
library(scales)
library(ggnewscale)
```

# Functions
```{r}
reduce_all_numeric <- function(liste) {
  for (i in 1:length(liste)) {
    liste[i] <- as.numeric(liste[[i]][1])
  }
  liste
}

Get_outliers <- function(vcf_path, pcadapt, filename, save = FALSE){
  vcf_to_catalog_ranks <- paste0(vcf_path, "/populations.snps.vcf") |> 
    read.vcfR() |>
    getID() |>
    strsplit(split = ":") |>
    reduce_all_numeric()
  
  #Outliers selection by pcadapt pvalues
  padj <- pcadapt$pvalues |> p.adjust(method = "bonferroni")
  outliers_vcf_ranks <- which(padj < .1) #alpha = .1 chosen following https://bcm-uga.github.io/pcadapt/articles/pcadapt.html recommendations
  
  #Getting outliers catalog ranks
  outliers_catalog_ranks <- vcf_to_catalog_ranks[outliers_vcf_ranks]
  
  #Separating balancing selection from local adaptation (sorting outliers by phi_st)
  outliers_phi_st_filtered <- read.table(
    file             = paste0(vcf_path, "/populations.phistats.tsv"),
    header           = FALSE,
    sep              = "\t",
    skip             = 9,
    stringsAsFactors = FALSE
  ) |>
    select(c(1, 4)) |>
    rename("catalog_rank" = V1, "phi_st" = V4) |> 
    filter(catalog_rank %in% outliers_catalog_ranks) |>
    filter(phi_st > .1)
  print(
    paste0(
      "There are ",
      dim(outliers_phi_st_filtered)[1],
      " outliers with a phi_st > 0.1."
    )
  )
  #Saving outliers list as txt file for stacks2 whitelist analysis
  if (save == TRUE) {
    sink(here("output", paste0(filename, "_outliers_catalog_ranks.txt")))
    for (outlier in outliers_catalog_ranks){
      cat(paste0(outlier, "\n"), append = TRUE)
    }
    sink()
    print(
      paste0(
        "Outliers list saved as ",
        here("output", paste0(filename, "_outliers_catalog_ranks.txt"))
      )
    )
  }
  outliers_catalog_ranks
}

XML_to_DF <- function(XML){
  # Initialisation
  end <- length(xml_find_all(XML, ".//BlastOutput2"))
  counter <- 0
  query_df <- data.frame()
  # Main loop
  for (query in xml_find_all(XML, ".//BlastOutput2")) { # Reads XML BLAST results as data frame
    counter <- counter + 1
    # query_id <- 
    print(paste0("Extracting query ", counter, "/", end))
    print("Parsing hits")
    for (Hit in xml_find_all(query, ".//Hit")) { # For each locus get all hits
      match_1 <- xml_find_all(Hit, ".//Hsp") |> _[1] # Keep best match
      new_row <- data.frame(
        "query_number"     = xml_find_all(query, ".//query-title") |>
          xml_text() |> 
          as.numeric(),
        "hit_number"       = xml_find_all(Hit, ".//num") |>
          xml_text() |>
          _[1] |> 
          as.numeric(),
        "accession_number" = xml_find_all(Hit, ".//accession") |>
          xml_text() |>
          _[1],
        "title"            = xml_find_all(Hit, ".//title") |>
          xml_text() |>
          _[1],
        "organism"         = xml_find_all(Hit, ".//sciname") |>
          xml_text() |>
          _[1],
        "bit_score"        = xml_find_all(match_1, ".//bit-score") |>
          xml_text() |>
          as.numeric(),
        "eval_number"      = xml_find_all(match_1, ".//evalue") |>
          xml_text() |>
          as.numeric()
      )
      query_df_short <- query_df |>
        bind_rows(new_row)
    }
    print("End of parsing")
  }
  query_df
}
```

# pcadapt analysis

## pcadapt pre-analysis to chose K value for outliers selection

```{r }
EJA_all_loci <- read.pcadapt(# Read vcf file for every loci
  here("ustacks_populations_output", "all_loci", "populations.snps.vcf"),
  type = "vcf"
)

pcadapt_all_loci_raw <- pcadapt(input = EJA_all_loci, K = 20)
plot(pcadapt_all_loci_raw, option = "screeplot") #screeplot to visually chose pca component to keep

# K = 3 seems to be the most optimal for this data set
```

## Analysis with optimal value of K

```{r }
pcadapt_all_loci <- pcadapt(input = EJA_all_loci, K = 3)

poplist.names <- c(
  rep("carmel", 6),
  rep("monterey", 18),
  rep("palos_verdes", 9),
  rep("laguna", 9),
  rep("san_diego", 22),
  rep("catalina", 8),
  rep("punta_banda", 20),
  rep("cardon", 3)
) #map individuals to populations

plot(pcadapt_all_loci, option = "scores", pop = poplist.names, i = 1, j = 2)
plot(pcadapt_all_loci, option = "scores", pop = poplist.names, i = 2, j = 3)
plot(pcadapt_all_loci, option = "scores", pop = poplist.names, i = 1, j = 3)

plot(pcadapt_all_loci, option = "qqplot")
hist(
  pcadapt_all_loci$pvalues,
  xlab = "p-values",
  main = NULL,
  breaks = 50,
  col = "orange"
)
```

## Getting outliers

```{r}
EJA_outliers_catalog_ranks <- Get_outliers(
  here("ustacks_populations_output", "all_loci"),
  pcadapt  = pcadapt_all_loci,
  filename = "EJA",
  save = FALSE
)
```

## pcadapt analysis with blacklist (neutral loci)

```{r}
EJA_blacklist <- read.pcadapt(
  here("ustacks_populations_output", "EJA_blacklist", "populations.snps.vcf"),
  type = "vcf"
)
pcadapt_blacklist_raw <- pcadapt(input = EJA_blacklist, K = 20)

plot(pcadapt_blacklist_raw, option = "screeplot")
plot(
  pcadapt_blacklist_raw,
  option = "scores",
  pop = poplist.names,
  i = 1, j = 2
)
```

## pcadapt analysis with whitelist (outliers loci)

```{r}
EJA_whitelist <- read.pcadapt(
  here(
    "ustacks_populations_output",
    "EJA_whitelist_outliers",
    "populations.snps.vcf"
  ),
  type = "vcf"
)
pcadapt_whitelist <- pcadapt(input = EJA_whitelist, K = 20)

plot(pcadapt_whitelist, option = "screeplot")
plot(pcadapt_whitelist, option = "scores", pop = poplist.names, i = 1, j = 2)
```

## pcadapt without Catalina

```{r}
EJA_all_loci_catalina <- read.pcadapt(#Read vcf file for every loci
  here(
    "ustacks_populations_output",
    "EJA_all_loci-catalian",
    "populations.snps.vcf"
  ),
  type = "vcf"
)

pcadapt_all_loci_catalina_raw <- pcadapt(input = EJA_all_loci_catalina, K = 20) #pcadapt analysis with high value of K
plot(pcadapt_all_loci_catalina_raw, option = "screeplot") #screeplot to visually chose pca component to keep

##K = 2 seems to be the most optimal for this data set

pcadapt_all_loci_catalina <- pcadapt(input = EJA_all_loci_catalina, K = 2)

poplist.names <- c(
  rep("carmel", 6),
  rep("monterey", 18),
  rep("palos_verdes", 9),
  rep("laguna", 9),
  rep("san_diego", 22),
  rep("punta_banda", 20),
  rep("cardon", 3)
) #map individuals to populations

plot(
  pcadapt_all_loci_catalina,
  option = "scores",
  pop = poplist.names,
  i = 1, j = 2
)
100*pcadapt_all_loci_catalina$singular.values**2
```

## Outliers without Catalina

```{r}
EJA_catalina_outliers_catalog_ranks <- Get_outliers(
  vcf_path = here("ustacks_populations_output", "EJA_all_loci-catalian"),
  pcadapt  = pcadapt_all_loci_catalina,
  filename = "EJA_catalina"
)
```

# Getting protein sequences for outliers

##Import and format the catalog

```{r}
#Read and prepare catalog fasta file
catalog_sequences <- read.csv(
  here("data", "catalog.fa"),
  col.names = c("Sequences"),
  stringsAsFactors = FALSE
) |> 
  filter(row_number() %% 2 != 0) |> 
  mutate("catalog_rank" = row_number()) |> 
  select(catalog_rank, Sequences)

print(length(EJA_outliers_catalog_ranks)) # Plot number of outliers

outliers_sequences <- catalog_sequences |>
  filter(row_number() %in% EJA_outliers_catalog_ranks)

# outliers_sequences <- subset(
#   catalog_sequences,
#   rownames(catalog_sequences) %in% EJA_outliers_catalog_ranks
# ) # Extracting sequences of outliers
head(outliers_sequences)
write.csv(outliers_sequences, file = here("output", "outliers_sequences.csv"))
```

## Saving results as .fa fasta file for NCBI BLAST

```{r}
sink(here("output", "outliers_sequences.fa"))
for (i in 1:dim(outliers_sequences)[1]){
  cat(paste0(">", outliers_sequences$catalog_rank[i], "\n"), append = TRUE)
  cat(paste0(outliers_sequences$Sequences[i], "\n"), append = TRUE)
}
sink()
```

Please use the generated fasta file for NCBI BLAST analysis and download the result as Single-file XML2

## Import BLAST results saved as xml file and extract results

Please replace the second line of the XML file by "<BlastXML2>" which effectively removes the metadata from the first xml tag.

```{r}
query_df <- read_xml(here("data", "8R1WY2TK01N-Alignment.xml")) |> XML_to_DF()
query_df |> saveRDS(file = here("output", "Blast_results_as_data_frame.RDS"))
```


## Filtering BLAST results

```{r}
query_df_80_test <- query_df |> filter(bit_score >= 80)
query_df_80 <-query_df[query_df$bit_score >= 80, ] #Keep only significant matches
dim(query_df_80)[1]
query_df_80_PREDICTED <- query_df_80[grepl("PREDICTED", query_df_80$title), ] #keep only PREDICTED proteins. Removes non coding sequences and whole chromosome matches (causes problem when searching GeneBank)
dim(query_df_80_PREDICTED)[1]
query_df_80_PREDICTED_unique <-
  query_df_80_PREDICTED[!duplicated(query_df_80_PREDICTED$query_number), ] #Keep the first match for each locus
dim(query_df_80_PREDICTED_unique)[1]
query_df_80_PREDICTED_unique_unique <-
  query_df_80_PREDICTED_unique[!duplicated(query_df_80_PREDICTED_unique$accession_number), ] #Removes duplicated accession numbers
dim(query_df_80_PREDICTED_unique_unique)[1]

# write.csv(query_df_80_PREDICTED_unique_unique, file = here("output", "query_df_80_PREDICTED_unique_unique.csv"))
```

## Get protein sequences from GenBank

```{r}
# Initialisation
prot_sequences <- data.frame(
  "protein_sequence" = rep(
    NA,
    length(query_df_80_PREDICTED_unique_unique$accession_number)
  ),
  row.names          = query_df_80_PREDICTED_unique_unique$accession_number
)

pb <- txtProgressBar(min = 0, max = dim(prot_sequences)[1], initial = 0) #Setup progress bar
for (i in 1:dim(prot_sequences)[1]){
  sequence_info <- entrez_fetch(
    "nuccore",
    id     = rownames(prot_sequences)[i],
    rettype ="fasta_cds_aa",
    retmode = "text"
  ) #Fetch protein info from GenBank from accession number
  prot_sequences[rownames(prot_sequences)[i], ] <-
    gsub(
      pattern     = "\n",
      replacement = "",
      x           = tail(unlist(strsplit(sequence_info, "]")),1)
    ) #Extract protein sequence from information
  setTxtProgressBar(pb, i) #Update progress bar
}
close(pb)

# prot_sequences = subset(x = prot_sequences, !(subset = prot_sequences$protein_sequence == ""))

#Write protein sequences as fasta file with GenBank access number as sequence names
sink(here("output", "outliers_protein_sequences.fa"))
for (i in 1:dim(prot_sequences)[1]){
  cat(paste0(">", rownames(prot_sequences)[i], "\n"), append = TRUE)
  cat(paste0(prot_sequences$protein_sequence[i], "\n"), append = TRUE)
}
sink()
```

## Outliers protein match table

```{r}
Table_2 <-
  query_df_80_PREDICTED_unique_unique[
    ,
    c(
      "query_number",
      "accession_number",
      "title"
    )
  ]
colnames(Table_2)[1] <- "Locus_ID"
write.csv(x = Table_2, file = here("output", "Table_2.csv"), row.names = FALSE)
```

# Figures plotting

## Manhattan plot homemade

### Formatting data

```{r}
# Getting chromosome map for manhatan plot
chromosome.names <- EJA_all_loci_vcf |>
  getFIX() |>
  _[, "CHROM"] |> # Get chromosome for each vcf locus
  lapply(FUN = gsub, pattern = "SCAF_", replacement = "") |>
  as.integer()

# Extract chromosome number from vcf info

# Getting x axis coordinates for chromosome id positions
mid_pos <- rep(NA, 24) # Initialise midrank vector
count_pos <- as.data.frame(table(chromosome.names)) # Number of locus per chromosome

for (i in 1:24){
  mid_pos[i] <-
    Position(function(x) x == i, chromosome.names) + count_pos$Freq[i]/2
}

notNA.idx <- !is.na(pcadapt_all_loci$pvalues) 
chr.int <- chromosome.names%%2 # Colour mapping for chromosomes. Grey or black depending on parity

manhattan_df <- data.frame(
  x   = which(notNA.idx), # Catalog rank of locus with non-NA pcadapt p-value 
  y   = -as.numeric( # Gets non adjusted -log10(pvalues) without infinite values
    pchisq(
      pcadapt_all_loci$chi2.stat[notNA.idx],
      df         = attr(pcadapt_all_loci, "K"),
      lower.tail = FALSE,
      log.p      = TRUE
    )/log(10)
  ), 
  chr = chr.int[notNA.idx] # Chromosome colour mapping
)
```

### Generate plot without points labels

```{r}
manhattan_plot <- ggplot(manhattan_df, aes(x = x, y = y)) +
  geom_point(aes(colour = factor(manhattan_df$chr))) +
  guides(colour = FALSE) +
  scale_color_manual(values = c("black", "grey")) +
  scale_x_continuous(breaks = mid_pos, labels = 1:24) +
  labs(x = "chromosome", y = "-log10(p-value)") +
  theme_bw() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  )

ggsave(
  here("output", "plots", "manhattan_plot.pdf"),
  plot = manhattan_plot,
  width = 16,
  height = 7
)
system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "manhattan_plot.pdf")),
  wait = FALSE
)
```

### Generate plot with points labels

```{r}
EJA_outliers_pvalues_rank <- data.frame(
  "vcf_rank"                 = EJA_outliers_vcf_ranks,
  "catalog_rank"             = as.character(EJA_outliers_catalog_ranks),
  "outliers_-log10(pvalues)" = -log10(
    pcadapt_all_loci$pvalues[EJA_outliers_vcf_ranks]
  ),
  "outliers_pvalue_plot"     = manhattan_df$y[manhattan_df$x %in% EJA_outliers_vcf_ranks]
)

manhattan_plot_labels <- manhattan_plot +
  geom_label_repel(
    data    = EJA_outliers_pvalues_rank,
    mapping = aes(x = vcf_rank, y = outliers_pvalue_plot, label = catalog_rank)
  ) #Manhattan plot with outliers catalog ranks

ggsave(
  here("output", "plots", "manhattan_plot_labels.pdf"),
  plot = manhattan_plot_labels,
  width = 16,
  height = 7
); system2(
  "open",
  args = c(
    "-a Preview.app",
    here("output", "plots", "manhattan_plot_labels.pdf")
  ),
  wait = FALSE
)
```

## Figure 1

### PCA plot

#### Data formatting

```{r}
PCA_df <- data.frame(
  "x" = -pcadapt_all_loci$scores[, 1],
  "y" = -pcadapt_all_loci$scores[, 2],
  "pop" = poplist.names
)

PCA_average <- data.frame("pop" = levels(as.factor(poplist.names)))
for (i in 1:length(PCA_average$pop)){
  PCA_average$average_x[i] <-
    mean(PCA_df[PCA_df$pop == PCA_average$pop[i], "x"])
  PCA_average$average_y[i] <-
    mean(PCA_df[PCA_df$pop == PCA_average$pop[i], "y"])
}
PCA_average$pop <- c( # Rename populations with human readable syntax
  "Cardon",
  "Carmel",
  "Catalina",
  "Laguna Beach",
  "Monterey Bay",
  "Palos Verdes",
  "Punta Banda",
  "San Diego"
)
# Add ofsets
PCA_average$average_x <- PCA_average$average_x + c(0, -.02, .015, 0, 0, 0, 0, 0)

PCA_average$average_y <-
  PCA_average$average_y - c(.04, .01, -.01, .06, .06, .06, .055, .045)

PCA_percentages <- pcadapt_all_loci$singular.values^2
```

#### Generate plot

```{r}
PCA <- ggplot() +
  geom_point(
    PCA_df,
    mapping = aes(x = y, y = x, fill = pop),
    size = 3,
    shape = 21
  ) +
  geom_text(
    PCA_average,
    mapping = aes(x = average_y, y = average_x, label = pop)
  ) +
  labs(
    x = paste0("-PC2: ", as.character(round(PCA_percentages[2]*100, 2)), "%"),
    y = paste0("-PC1: ", as.character(round(PCA_percentages[1]*100, 2)), "%")
  ) +
  coord_fixed(ratio = 1.2) +
  theme(
    legend.position  = "none",
    panel.background = element_rect(
      fill = "white",
      color = "black"
    ),
    panel.grid.major = element_line(
      color = "black",
      linetype = "dashed",
      linewidth = .12
    )
  )
```

### Surface temperature and current map

#### Getting data

```{r}
# Extracting ocean surface temperature and current from BRAN2020
# (https://dapds00.nci.org.au/thredds/catalog/gb6/BRAN/BRAN2020/month/catalog.html)
# See https://towardsdatascience.com/how-to-crack-open-netcdf-files-in-r-and-extract-data-as-time-series-24107b70dcd for tutorial on NetCDF4 files
nc_temp <- nc_open(here("data","ocean_temp_ann_2022.nc"))
# Longitude's 0 is at Greenwich and -180 become 3600
# Latitudes start at -75 and end at +75
# To convert add +360 to longitude and +75 to latitude
nc_u   <- nc_open(here("data", "ocean_u_ann_2022.nc"))
nc_v   <- nc_open(here("data", "ocean_v_ann_2022.nc"))
```

#### Formatting data

##### BRAN2020 data

```{r}
lon <- ncvar_get(nc_temp, "xt_ocean")
lon[1801:3600] <- seq(-179.95,-0.05,.1)
lat <- ncvar_get(nc_temp, "yt_ocean") 
lonlat      <- expand.grid("lon" = lon, "lat" = lat) |> as.matrix()
temp_matrix <- nc_temp |> ncvar_get("temp") |>  _[, , 1] |> as.matrix()
u_matrix    <- nc_u |> ncvar_get("u") |> _[, , 1] |> as.matrix()
v_matrix    <- nc_v |> ncvar_get("v") |> _[, , 1] |> as.matrix()

world_map_data_df <- data.frame(# Final data frame for whole world
  lonlat,
  "temp" = as.vector(temp_matrix),
  "u"    = as.vector(u_matrix),
  "v"    = as.vector(v_matrix)
)

# Crop to smaller size for diminished render time
crop_lonlat <- expand.grid(
  "lon" = lon[(3600 - 1300):(3600 - 1100)],
  "lat" = lat[(200 + 750):(400 + 750)]
) |> as.matrix()
crop_temp   <- temp_matrix[
  (3600 - 1300):(3600 - 1100),
  (200 + 750):(400 + 750)
  ] |> as.vector()
crop_u      <- u_matrix[
  (3600 - 1300):(3600 - 1100),
  (200 + 750):(400 + 750)
  ] |> as.vector()
crop_v      <- v_matrix[
  (3600 - 1300):(3600 - 1100),
  (200 + 750):(400 + 750)
  ] |> as.vector()
# Reduce current speed vector density
crop_u_lowres <- replace(crop_u, list = 2 * 1:(length(crop_u)/2), values = NA)
crop_v_lowres <- replace(crop_v, list = 2 * 1:(length(crop_v)/2), values = NA)

map_data_lowres_df <- data.frame(# Final used data frame for map
  crop_lonlat,
  "temp" = crop_temp,
  "u"    = crop_u_lowres,
  "v"    = crop_v_lowres
)

rm(nc_temp, nc_u, nc_v, temp_matrix, u_matrix, v_matrix) # Clear unused big variables

current_uv_scalar <- 2 # Set scalar for better vector visibility, don"t forget when setting scale in final graph
```

##### Landmass

```{r}
# Setting up landmass map from naturalearth
world  <- ne_countries(
  scale       = "large",
  country     = c("united states of america", "mexico"),
  returnclass = "sf"
)
states <- ne_states(
  country     = c("united states of america", "mexico"),
  returnclass = "sf"
)

# Sampling site coordinates and misc info on map
sample_sites <-
  read.csv(
    here("data","EJA_RAD_Samples.csv"),
    stringsAsFactors = FALSE
  ) |>
  filter(!duplicated(Sampling_location)) |> 
  mutate(
    "lab_lon" = Longitude + .15 + c(0, 0, 0, .1, 0, 0, 0, -.1 -2),
    "lab_lat" = Latitude + .25 + c(0, -.5, 0, -.2, 0, 0, 0, -.1 -1)
  )

states_labels <- data.frame(
  "long" = c(-117.5, -115.5, -113.7, -115.2),
  "lat"  = c(35.5, 36.6, 35, 30.25),
  "lab"  = c("CA", "NV", "AZ", "BC")
)
city_labels <- data.frame(
  "lat"      = c(37.773972, 34.448113),
  "long"     = c(-122.431297, -120.471439),
  "lat_lab"  = c(37.9, 34.8),
  "long_lab" = c(-122.28, -120.535),
  "lab"      = c("San Francisco", "Point\nConception")
)
ocean_labels <- data.frame(
  "long" = c(-121,-113.85),
  "lat"  = c(31,30.7),
  "lab"  = c("Pacific Ocean","Gulf\nof\nCalifornia")
)
```

#### Generate map

```{r}
map <- ggplot() +
  #Temperature map (https://theoceancode.netlify.app/post/mapping_with_ggplot2/)
  geom_tile(
    mapping = aes(x = lon, y = lat, fill = temp),
    data =  map_data_lowres_df
  ) +
  scale_fill_viridis(name = "Temp.\n(¬∞C)", option = "turbo") +
  #Current vectors (https://theoceancode.netlify.app/post/mapping_with_ggplot2/)
  geom_segment(
    data    = map_data_lowres_df,
    mapping = aes(
      x    = lon,
      y    = lat,
      xend = lon + current_uv_scalar * u,
      yend = lat + current_uv_scalar * v
    ),
    arrow   = arrow(angle = 15, length = unit(0.04, "inches"), type = "closed"),
    na.rm   = TRUE,
    alpha   = 0.3
  ) +
  #Landmass
  geom_sf(data = states) +
  #Sampling sites points and labels
  new_scale("fill") +
  geom_path(
    data.frame(
      "x" = c(-118.4163, -118.4163 -.85),
      "y" = c(33.38790, 33.38790 -.73)
    ),
    mapping = aes(x, y)
  ) +
  geom_point(
    sample_sites,
    mapping     = aes(
      x = Longitude,
      y = Latitude,
      fill = Sampling_location,
      size = 1.3
    ),
    shape       = 21,
    show.legend = FALSE
  ) +
  geom_label(
    sample_sites,
    mapping = aes(x = lab_lon, y = lab_lat, label = Sampling_location),
    hjust   = 0
  ) +
  #Extra cities points and labels
  geom_point(
    city_labels,
    mapping     = aes(x = long, y = lat),
    size        = 4,
    shape       = 20,
    show.legend = FALSE
  ) +
  geom_text(
    city_labels,
    mapping    = aes(x = long_lab, y = lat_lab, label = lab),
    lineheight = .7,
    hjust      = 0
  ) +
  #Ocean and state names
  geom_text(
    states_labels,
    mapping = aes(x = long, y = lat, label = lab),
    size = 5.5
  ) +
  geom_text(
    ocean_labels[2,],
    mapping = aes(x = long, y = lat, label = lab),
    colour  = "ivory",
    size    = 5
  ) +
  geom_label(
    ocean_labels[1,],
    mapping       = aes(x = long, y = lat, label = lab),
    colour        = "black",
    size          = 5,
    label.padding = unit(0.5, "lines")
  ) +
  #Crop map 
  coord_sf(xlim = c(-124, -113), ylim = c(28.5, 38.5), expand = FALSE) +
  #Vector, temperature and distance scale + orientation
  geom_label(
    aes(x = -122, y = 29.5, label = "1.0 m/s\n"),
    size          = 4.5,
    label.padding = unit(0.5, "lines")
  ) +
  geom_segment(
    aes(x = -122.5, y = 29.25, xend = -121.5, yend = 29.25),
    arrow = arrow(angle = 15, length = unit(0.04, "inches"), type = "closed")
  ) +
  geom_label(aes(x = -119.1, y = 28.71, label = "        ")) +
  annotation_scale(location = "bl", width_hint = 0.4) +
  annotation_north_arrow( # Set text around map and coordinates display
    location = "tr",
    style = north_arrow_fancy_orienteering()
  ) +
  labs(x = "Longitude", y = "Latitude") +
  scale_x_continuous(
    breaks = c(-120, -115),
    labels = c("120¬∞W","115¬∞W")
  ) +
  scale_y_continuous(
    breaks = c(30, 35),
    labels = unit_format(suffix = "¬∞N", sep = "")
  )

ggsave(
  here("output", "plots", "temp_current_map.pdf"),
  plot   = map,
  width  = 9,
  height = 9
)
system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "temp_current_map.pdf")),
  wait = FALSE
)
```

### Fusing PCA plot and map

```{r}
PCA_map <- ggarrange(PCA, map, widths = c(1, 1.3))

ggsave(
  here("output", "plots", "pca_map.pdf"),
  plot   = PCA_map,
  width  = 14,
  height = 9
)
system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "pca_map.pdf")),
  wait = FALSE
)
```

## Figure 2?

### Generating bathymetry map

#### Getting and formatting data

```{r}
catalina_df <-
  getNOAA.bathy(
    lon1 = -121,
    lon2 = -116,
    lat1 = 32,
    lat2 = 35,
    resolution = .5
  ) |> 
  fortify.bathy() |>
  mutate(z = ifelse(z > 0, NA, z)) # Remove landmass data

map_data_df <- data.frame( # Get surface current vectors
  crop_lonlat,
  "u" = crop_u,
  "v" = crop_v
)
```

#### Generate map

```{r}
bathy <- ggplot() +
  geom_raster(data = catalina_df, mapping = aes(x = x, y = y, fill = z)) + # Plot bathymetry
  geom_sf(data = states) + # Plot landmass
  geom_segment( # Plot surface current speed
    data    = map_data_df,
    mapping = aes(x = lon, y = lat, xend = lon + u * 1, yend = lat + v * 1),
    arrow   = arrow(angle = 15, length = unit(0.04, "inches"), type = "closed"),
    na.rm   = TRUE,
    alpha   = 0.3
  ) +
  geom_point( # Plot sampling sites
    sample_sites[c(3,4,5,8),],
    mapping     = aes(x = Longitude, y = Latitude, size = 1.3),
    show.legend = FALSE
  ) +
  geom_label(
    sample_sites[c(3,4,5,8),],
    mapping = aes(x = Longitude, y = Latitude, label = Sampling_location),
    hjust   = 0,
    nudge_x = .05,
    nudge_y = .1
  ) +
  geom_point( # Plot extra landmark
    city_labels[2, ],
    mapping     = aes(x = long, y = lat),
    size        = 4,
    shape       = 20,
    show.legend = FALSE
  ) +
  geom_text(
    city_labels[2, ],
    mapping = aes(x = long, y = lat, label = lab),
    lineheight = .7,
    hjust = 0,
    nudge_x = .05,
    nudge_y = .1
  ) +
  scale_fill_gradient(# Plot scales
    name = "Depth (m)",
    low = "dodgerblue4",
    high="gainsboro"
  ) +
  geom_label(
    aes(x = -120.4, y = 32.3, label = ".25 m/s\n"),
    size = 4.5,
    label.padding = unit(0.5, "lines")
  ) +
  geom_segment(
    aes(x = -120.52, y = 32.25, xend = -120.27, yend = 32.25),
    arrow = arrow(angle = 15, length = unit(0.04, "inches"), type = "closed")
  ) +
  geom_label(aes(x = -119.705, y = 32.08, label = "        ")) +
  annotation_scale(location = "bl", width_hint = 0.4) +
  annotation_north_arrow(
    location = "tr",
    style    = north_arrow_fancy_orienteering()
  ) +
  coord_sf(xlim = c(-121, -116), ylim = c(32, 35), expand = FALSE) + # Crop map
  labs(x = "Longitude", y = "Latitude") +
  scale_y_continuous( # Axis labels and theme
    breaks = seq(32, 35, 1),
    labels = unit_format(suffix = "¬∞N", sep = "")
  ) +
  theme(
    legend.position = c(.93, .73),
    plot.margin     = margin(t = 0, r = 1, b = 0, l = .5, unit = "cm")
  )
  
ggsave(
  here("output", "plots", "bathy.pdf"),
  plot = bathy,
  width = 9,
  height = 7
)
system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "bathy.pdf")),
  wait = FALSE
)
```

### Generating map without specific background

```{r}
map_blank <- ggplot() +
  #Landmass
  geom_sf(data = states) +
  #Sampling sites points and labels
  new_scale("fill") +
  geom_path(
    mapping = aes(x, y),
    data    = data.frame(
      "x" = c(-118.4163, -118.4163 -.85),
      "y" = c(33.38790, 33.38790 -.73)
    )
  ) +
  geom_point(
    sample_sites,
    mapping     = aes(
      x    = Longitude,
      y    = Latitude,
      fill = Sampling_location,
      size = 1.3
    ),
    shape       = 21,
    show.legend = FALSE
  ) +
  geom_label(
    sample_sites,
    mapping = aes(x = lab_lon, y = lab_lat, label = Sampling_location),
    hjust   = 0
  ) +
  geom_point(
    city_labels,
    mapping     = aes(x = long, y = lat),
    size        = 4,
    shape       = 20,
    show.legend = FALSE
  ) +
  geom_text(
    city_labels,
    mapping    = aes(x = long_lab, y = lat_lab, label = lab),
    lineheight = .7,
    hjust      = 0
  ) +
  #Ocean and state names
  geom_text(
    states_labels,
    mapping = aes(x = long, y = lat, label = lab),
    size    = 5.5
  ) +
  geom_text(
    ocean_labels[2,],
    mapping = aes(x = long, y = lat, label = lab),
    colour  = "ivory",
    size    = 5
  ) +
  geom_label(
    ocean_labels[1,],
    mapping       = aes(x = long, y = lat, label = lab),
    colour        = "black",
    size          = 5,
    label.padding = unit(0.5, "lines")
  ) +
  #Crop map 
  coord_sf(xlim = c(-124, -113), ylim = c(28.5, 38.5), expand = FALSE) +
  #Vector, temperature and distance scale + orientation
  geom_label(aes(x = -119.1, y = 28.71, label = "        ")) +
  annotation_scale(location = "bl", width_hint = 0.4) +
  annotation_north_arrow(
    location = "tr",
    style = north_arrow_fancy_orienteering()
  ) +
  #Set text around map and coordinates display
  labs(x = "Longitude", y = "Latitude") +
  scale_x_continuous(
    breaks = c(-120, -115),
    labels = c("120¬∞W","115¬∞W")
  ) +
  scale_y_continuous(
    breaks = c(30, 35),
    labels = unit_format(suffix = "¬∞N", sep = "")
  ) +
  theme(panel.background = element_rect("lightblue"))

ggsave(
  here("output", "plots", "map_blank.pdf"),
  plot = map_blank,
  width = 7.5,
  height = 7.5
)

system2(
  "open",
  args = c("-a Preview.app", here("output", "plots", "map_blank.pdf")),
  wait = FALSE
)
```

## Figure 3?

### Convert blast KOALA pie piechart in barplot

```{r}
koala_results <- read.csv(
  here("external_results", "Blast_koala_results.csv"),
  stringsAsFactors = FALSE
) |>
  mutate(
    Functional.category = factor(Functional.category, Functional.category)
  )

koala_barplot <- ggplot(
    koala_results,
    mapping = aes(
      x = Functional.category,
      y = Counts,
      fill = Functional.category
    )
  ) +
  geom_col() +
  # scale_fill_discrete(name = "Functional category") +
  scale_fill_manual(
    name   = "Functional category",
    labels = koala_results$Functional.category,
    values = koala_results$colour,
    breaks = koala_results$Functional.category
  ) +
  theme(
    panel.background   = element_rect(fill = "white", colour = "black"),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_line(
      colour = "black",
      linetype = "solid",
      linewidth = .12
    ),
    panel.grid.minor.y = element_line(
      colour = "black",
      linetype = "dashed",
      linewidth = .08
    ),
    axis.ticks.x      = element_blank(),
    axis.text.x       = element_blank(),
    axis.title.x      = element_blank()
  )
ggsave(
  filename = here("external_results", "blast_koala_bar_plot.pdf"),
  plot = koala_barplot,
  width = 21,
  height = 10,
  units = "cm"
)
system2(
  "open",
  args = c("-a Preview.app", here("external_results", "blast_koala_bar_plot.pdf")),
  wait = FALSE
)
```
